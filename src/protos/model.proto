syntax = "proto2";
package protos;


import "feature_config.proto";
import "deepfm.proto";
import "loss.proto";

// for input performance test
message DummyModel {

}

// for knowledge distillation
message KD {
  optional string loss_name = 10;
  required string pred_name = 11;
  // default to be logits
  optional bool pred_is_logits = 12 [default=true];
  // for CROSS_ENTROPY_LOSS, soft_label must be logits instead of probs
  required string soft_label_name = 21;
  // default to be logits
  optional bool label_is_logits = 22 [default=true];
  // currently only support CROSS_ENTROPY_LOSS and L2_LOSS
  required LossType loss_type = 3;
  optional float loss_weight = 4 [default=1.0];
  // only for loss_type == CROSS_ENTROPY_LOSS
  optional float temperature = 5 [default=1.0];

}

message Model {
    required string model_class = 1;

    // actually input layers, each layer produce a group of feature
    repeated FeatureGroupConfig feature_groups = 2;

    // model parameters
    oneof model {
        DummyModel dummy = 101;
        DeepFM deepfm = 103;

    }
    repeated SeqAttGroupConfig seq_att_groups = 7;
    // implemented in easy_rec/python/model/easy_rec_estimator
    // add regularization to all variables with "embedding_weights:"
    // in name
    optional float embedding_regularization = 8 [default = 0.0];

    optional LossType loss_type = 9 [default = CLASSIFICATION];

    optional uint32 num_class = 10 [default = 1];

    optional bool use_embedding_variable = 11 [default=false];

    repeated KD kd = 12;

    // filter variables matching any pattern in restore_filters
    // common filters are Adam, Momentum, etc.
    repeated string restore_filters = 13;

//    optional VariationalDropoutLayer variational_dropout = 14;

    repeated Loss losses = 15;

    optional F1ReweighedLoss f1_reweight_loss = 16;
}
